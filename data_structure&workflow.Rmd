---
title: "Data Format, Structure, and Workflows"
author: "Maxim Grigri"
date: "May 3, 2021"
output: html_document
---

# General Data Format and Preparation

***

make a small change 

This document summarizes general formatting and preparation guidelines for all data
shared and uploaded to fortedata. It then provides a workflow for data to be uploaded 
to the shared forte google drive using the 'googledrive' R package.

## Naming files and folders

1. Names should be lowercase with "_" separating words.
2. File Type: CSV (Comma delimited)
3. Filenames: "level_data_type_year.csv" (i.e. "raw_canopy_dendroband_2019.csv")
+ level = raw, fd (fortedata), or gd (googledrive); fd is reformatted raw data that is fortedata ready, gd is raw data pulled from google drive (intermediate step)
4. Folder Names: "data_type" (i.e. "canopy_dendroband")
5. Include EML approved word document metadata file in each folder (Thanks JT!)
5. Each year should be 1 data file (but does this make sense for instrument data? Thoughts on this?)

## General File Structure and Format

1. Each row is one observation
2. Column names should:
  + Be lowercase with "_" separating words 
  + Include units if quantitative (i.e. "DBH_cm"; Flux units excluded)
  + Be documented in metadata (**fortedata**: added to `forte_table_metadata.csv`) 
3. Required columns:
  + Experimental unit id (i.e. plot/subplot)
  + **fortedata**: subplot_id -- replicate ("A-") plot ("-01-") subplot ("-E") (i.e   "A01E")
  + **SHOULD NOT** include separate replicate, plot, and subplot columns
  + date -- Date of data collection (YYYY-MM-DD)
  + notes

***

## Data Workflow: Field data to FoRTE share google drive folder as an example

1. Use google "Back Up and Sync" to backup your local data folder to google drive 
  + This ensures all your data and scripts are backed up incase your local machine dies
  or you throw it in the James or "accidently" drop in the can when R is giving you a hard time.
  + A couple things to note: 1) You can find this backed-up folder in the "Computers", "My Laptop"
  tab on your google drive. 2) You can create a shortcut (right click, "Add shortcut to drive") and add 
  it to "My Drive" and likewise a shared folder. 3) When working on an R project, R hates the constant updates to google drive, so you have to pause "Back Up and Sync" while working on a project. Just make sure to resume updates after to ensure all of your work is backed up!  
2. FoRTE or LTREB will differ slightly, but for either, make sure the raw data files are available in
  a shared google drive folder (i.e. FoRTE or LAB). There are 2 ways to do this:
  + Ideally, create a shortcut of your backed up folder (right click, "Add shortcut to drive") and add it to a shared folder. This way, as you update your data file, the updates/new data are automatically backed up to the shared folder. 
  + Alternately, you can copy the data file into a shared folder OR upload it to a shared folder from your     local machine. This works fine for say a full years worth of data from prior field seasons, or uploading     your data at the end of a season to a **shared folder** (BUT your data is already backed up to google drive because of step 1 above, right!?)  
  
Okay, (sigh) now your raw data is safe, backed up, and shared with the group. Ideally all data products are properly formatted and structured from the start of data collection, BUT oops, sometimes it kinda looks like poo-poo and it needs some fine-tuning because you didn't read my carefully thought out General Data Format section above. It's okay, there's an app for that (just kidding, but there is this fun script I wrote up!). 

3. Here is an example "cleaning" script used to get subcanopy diameter data into proper format for the fortedata package. Most important is the 1) Use of the `googledrive` package to move (somewhat) smoothly between R to google drive, and 2) some examples of using base R for reformatting (Who ever uses base R!?). In the example of fortedata, there are a few steps you might have to take before using this code below.

  + Make sure that the "FoRTE" shared google drive folder is in "My Drive"
  + Click the dropdown menu next to "My Drive". If FoRTE is listed there, you can skip the following steps.
  + If FoRTE is not there:
  + Click "Shared with me"" (assuming this folder was shared with you at some point) and locate the FoRTE shared folder.
  + Right click and select "Add Shortcut to Drive". Now you can access this shared folder from "My Drive" using the `googledrive` R package.

```{r cleaning, include=TRUE, eval=FALSE}
# this script is an ingestion script for the subcanopy diameter data. In this example, 
# you can see I've used only base r to reduce dependencies with packages like dplyr

# first step is to install and load the library(googledrive). THis chunk should do that for ya!
if (!require("googledrive")) {
  install.packages("googledrive")
}
library(googledrive)

# Now the workflow here is a bit clunky, butit's the best I could figure out using the
# google drive package.To summarize, because of the steps above, our data is good and backed up to 
# the shared FoRTE google drive folder. While you probably have a copy of the raw data file
# Saved locally on your machine, resist the temptation to source your data locally and use 
# this package to bring in that remote copy from the shared drive. First, we download the raw
# data file from drive, then we make the formatting changes we want, and last we upload a new 
# level 1 version of our data that is nice and pretty and ready to be shared and used by 
# all the talented scientists out there desperate for our invaluable data. 

# This brings in raw data from the google drive. First I need to id the files I want.
# An easy way to do this is as follows. q = "starred = true" gets me the file I want quickly,
# but first I need to navigate to the file in My Drive, right click, and select "Add to Starred"

# Let's do this for the 2019 data 
file_id <- drive_find(type = "csv", pattern = "subcanopy_D.csv", q = "starred = true")
sc_2019_id <- file_id[[1,2]]

# Now for the 2020
file_id <- drive_find(type = "csv", pattern = "subcanopy_D_2020.csv", q = "starred = true")
sc_2020_id <- file_id[[1,2]]

# now I need to download this file and save it to my local data folder. Since I probably 
# (in my case definitely...) already have a version of this file, I'll name it something
# different. In this case, I'll use gd for google drive

# alright, first for the 2019
drive_download(
  as_id(sc_2019_id), 
  path = "data/gd_subcanopy_D.csv",
  overwrite = FALSE)

# and tnow the 2020
drive_download(
  as_id(sc_2020_id), 
  path = "data/gd_subcanopy_D_2020.csv",
  overwrite = FALSE)

# This brings in the data from my local machine
sc_2019 <- read.csv("data/gd_subcanopy_D.csv", na.strings = c("", "NA"))
sc_2020 <- read.csv("data/gd_subcanopy_D_2020.csv", na.strings = c("", "NA"))

# since 2020 is more tidy, I will start there and then reformat 2019 to match it 
# First step will be to rename column names to match other fortedata products 

# seperate the uniqueID column into subplot and nested_subplot
# this creates a new nested_subplot column and creates a notes column to match 2019
# *see my data was kind of messy! My uniqueID column did not match fortedata requirements
#  and I was missing a notes column in 2020
sc_2020$nested_subplot <- substr(sc_2020$uniqueID, 5, 5)
sc_2020$notes <- "NA"

# this deletes the nested subplot ID from the uniqueID column leaving only the subplot_id
sc_2020$uniqueID <- gsub('.$', '', sc_2020$uniqueID)

# make all column names lowercase 
names(sc_2020) <- tolower(names(sc_2020))

# now rename columns to match other forte data products
names(sc_2020)[names(sc_2020) == "uniqueid"] <- "subplot_id"
names(sc_2020)[names(sc_2020) == "subplotid"] <- "subplot_id"

# now drop unwanted columns and reorder 
sc_2020 <- sc_2020[c("subplot_id", "nested_subplot", "tag", "species", "dbh_mm", 
                     "date", "notes")]

# change 2020 to have same data classes for each vector; data classes 
# for variables already in fortedata metadata should conform to established classes 

# change 2020 nested to int, 2020 and 2019 date to date, 2020 notes to character
sc_2020$nested_subplot <- as.integer(sc_2020$nested_subplot)
sc_2020$date <- as.Date(sc_2020$date, "%Y-%m-%d")

#####################################################################################
# alright now they are properly formated and ready to go onto fortedata. 
# upload to google drive 

# first, write csv's. These will save in your 'data' folder and then you will upload
# them to google drive. Unfortunately there is not a way (that I know of...) to move
# directly from an R dataframe to google drive, so we need this intermediate step.
# Make sure to name them something different than the original files. In the case of 
# fortedata, use 'fd' at the start to signify it's ready to go to the package
write.csv(sc_2020, "data/fd_subcanopy_diameter_2020.csv", row.names = FALSE)

# find the folder pathway on mydrive and assign it to an object, in this case I called
# it 'y'
x <- drive_find(type = "folder", pattern = "subcanopy_diameter", n_max = 6)
y <- x[[1,2]]

# now upload using the file id we located above 
drive_upload(
  "data/fd_subcanopy_diameter_2020.csv", # this is the name of the file on your machine 
  name = "fd_subcanopy_diameter_2020", # this is the name of the file on googledrive
  path = as_id(y), # this identifies the path to which you've assigned the letter 'y'
  overwrite = TRUE # this overwrites a file with the same name in the googledrive
)

```

## Data Workflow: Google Drive to forte data 

1. Download local copy of fd_... (fortedata ready) csv file
2. Copy file into inst/extdata
3. Navigate to R/ folder and either find existing function call (i.e. fd_dendro) or create new function 
+ function should pull new csv file, append to other files, and reformat character classes, species codes, and other small fixes 
4. Add metadata to inst/extdata/forte_table_metadata.csv
5. Use Build > Check Package to diagnose and correct errors
+ I haven't figured out the Check CMD warnings, sorry! (aka ask BBL or Dr. Atkins)